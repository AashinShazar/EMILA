{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138 training part images.\n",
      "There are 9 validation part images.\n",
      "There are 26 test part images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "bigPath = 'C:\\\\Users\\\\aashi\\\\OneDrive\\\\Desktop\\\\school\\\\SFSU\\\\semester4 F19\\\\ENGR 478\\\\EMILA-CODE\\\\MachineLearning\\\\'\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    part_files = np.array(data['filenames'])\n",
    "    part_targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return part_files, part_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset(bigPath + 'train')\n",
    "test_files, test_targets = load_dataset(bigPath +'test')\n",
    "valid_files, valid_targets = load_dataset(bigPath +'valid')\n",
    "\n",
    "print('There are %d training part images.' % len(train_files))\n",
    "print('There are %d validation part images.' % len(valid_files))\n",
    "print('There are %d test part images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138/138 [00:02<00:00, 60.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 60.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 61.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aashi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_applications\\resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "\n",
    "model = applications.ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 150528)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               38535424  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 38,535,938\n",
      "Trainable params: 38,535,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 9 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 7.0893 - acc: 0.4928 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.12455, saving model to VGG16_Bench.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 8.3630 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.12455\n",
      "Epoch 3/100\n",
      " - 1s - loss: 8.4791 - acc: 0.4710 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.12455\n",
      "Epoch 4/100\n",
      " - 1s - loss: 8.4791 - acc: 0.4710 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.12455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 8.4214 - acc: 0.4746 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.12455\n",
      "Epoch 6/100\n",
      " - 1s - loss: 8.4214 - acc: 0.4746 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.12455\n",
      "Epoch 7/100\n",
      " - 1s - loss: 8.3685 - acc: 0.4746 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 7.12455\n",
      "Epoch 8/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.12455\n",
      "Epoch 9/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.12455\n",
      "Epoch 10/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.12455\n",
      "Epoch 11/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.12455\n",
      "Epoch 12/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.12455\n",
      "Epoch 13/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 7.12455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 7.12455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.12455\n",
      "Epoch 16/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.12455\n",
      "Epoch 17/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 7.12455\n",
      "Epoch 18/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 7.12455\n",
      "Epoch 19/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 7.12455\n",
      "Epoch 20/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 7.12455\n",
      "Epoch 21/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 7.12455\n",
      "Epoch 22/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.12455\n",
      "Epoch 23/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 7.12455\n",
      "Epoch 24/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 7.12455\n",
      "Epoch 25/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 7.12455\n",
      "Epoch 26/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 7.12455\n",
      "Epoch 27/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 7.12455\n",
      "Epoch 28/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 7.12455\n",
      "Epoch 29/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.12455\n",
      "Epoch 30/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 7.12455\n",
      "Epoch 31/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 7.12455\n",
      "Epoch 32/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 7.12455\n",
      "Epoch 33/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 7.12455\n",
      "Epoch 34/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 7.12455\n",
      "Epoch 35/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 7.12455\n",
      "Epoch 36/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 7.12455\n",
      "Epoch 37/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 7.12455\n",
      "Epoch 38/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 7.12455\n",
      "Epoch 39/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 7.12455\n",
      "Epoch 40/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 7.12455\n",
      "Epoch 41/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 7.12455\n",
      "Epoch 42/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 7.12455\n",
      "Epoch 43/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 7.12455\n",
      "Epoch 44/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 7.12455\n",
      "Epoch 45/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 7.12455\n",
      "Epoch 46/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 7.12455\n",
      "Epoch 47/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 7.12455\n",
      "Epoch 48/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 7.12455\n",
      "Epoch 49/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 7.12455\n",
      "Epoch 50/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 7.12455\n",
      "Epoch 51/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 7.12455\n",
      "Epoch 52/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 7.12455\n",
      "Epoch 53/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 7.12455\n",
      "Epoch 54/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 7.12455\n",
      "Epoch 55/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 7.12455\n",
      "Epoch 56/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 7.12455\n",
      "Epoch 57/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 7.12455\n",
      "Epoch 58/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 7.12455\n",
      "Epoch 59/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 7.12455\n",
      "Epoch 60/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_loss did not improve from 7.12455\n",
      "Epoch 61/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 7.12455\n",
      "Epoch 62/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 7.12455\n",
      "Epoch 63/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 7.12455\n",
      "Epoch 64/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 7.12455\n",
      "Epoch 65/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 7.12455\n",
      "Epoch 66/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 7.12455\n",
      "Epoch 67/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 7.12455\n",
      "Epoch 68/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 7.12455\n",
      "Epoch 69/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 7.12455\n",
      "Epoch 70/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 7.12455\n",
      "Epoch 71/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 7.12455\n",
      "Epoch 72/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 7.12455\n",
      "Epoch 73/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 7.12455\n",
      "Epoch 74/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 7.12455\n",
      "Epoch 75/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 7.12455\n",
      "Epoch 76/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 7.12455\n",
      "Epoch 77/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 7.12455\n",
      "Epoch 78/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 7.12455\n",
      "Epoch 79/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 7.12455\n",
      "Epoch 80/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 7.12455\n",
      "Epoch 81/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 7.12455\n",
      "Epoch 82/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 7.12455\n",
      "Epoch 83/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 7.12455\n",
      "Epoch 84/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 7.12455\n",
      "Epoch 85/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 7.12455\n",
      "Epoch 86/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 7.12455\n",
      "Epoch 87/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 7.12455\n",
      "Epoch 88/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 7.12455\n",
      "Epoch 89/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 7.12455\n",
      "Epoch 90/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 7.12455\n",
      "Epoch 91/100\n",
      " - 1s - loss: 8.3052 - acc: 0.4819 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 7.12455\n",
      "Epoch 92/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 7.12455\n",
      "Epoch 93/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 7.12455\n",
      "Epoch 94/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 7.12455\n",
      "Epoch 95/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 7.12455\n",
      "Epoch 96/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 7.12455\n",
      "Epoch 97/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 7.12455\n",
      "Epoch 98/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 7.12455\n",
      "Epoch 99/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 7.12455\n",
      "Epoch 100/100\n",
      " - 1s - loss: 8.3636 - acc: 0.4783 - val_loss: 7.1246 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 7.12455\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "epochs = 100\n",
    "batch_size=20\n",
    "\n",
    "bestModelSavedName = \"ResNet50_Bench.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=bestModelSavedName, \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets), \n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXWV97/HPd26ZTEjIhSFCIiRWBUyAQAYbpRcsSAkI2IISAWupgrxefR3EWitilVbbHls9tbVqMSrVnsOJCgSLHq8o0IuAJiHITQoIgSSQTAK5J2T23r/zx1qzs9mz9549w6xMstf3/XrNK7PXetZav5WVPL/9PM9az1JEYGZmBtA23gGYmdmBw0nBzMzKnBTMzKzMScHMzMqcFMzMrMxJwczMypwUzJok6auS/qrJsk9JOuPl7sdsf3NSMDOzMicFMzMrc1KwlpJ223xQ0i8k7ZT0FUkzJX1P0nZJt0uaVlH+PEkPSdoi6U5Jx1WsO0nSqnS7bwDdVcd6i6TV6bY/lXTCKGO+XNLjkp6XdJukI9PlkvQZSRslbU3PaX667mxJD6exrZP0p6P6CzOr4qRgregC4M3Aa4Fzge8B1wKHkfybvwpA0muBZcDVQC/wXeDbkrokdQHfAv43MB24Kd0v6bYnAzcA7wVmAF8EbpM0YSSBSvod4H8CbweOANYAX09Xnwn8VnoeU4GLgM3puq8A742IycB84CcjOa5ZPU4K1or+KSI2RMQ64D+AeyPivoh4EbgVOCktdxHw/yLiRxExAHwamAi8EVgEdAL/EBEDEXEz8POKY1wOfDEi7o2IYkR8DXgx3W4kLgFuiIhVaXwfBt4gaQ4wAEwGjgUUEY9ExLPpdgPA6yRNiYgXImLVCI9rVpOTgrWiDRW/767x+ZD09yNJvpkDEBEl4BlgVrpuXbx0xsg1Fb8fDXwg7TraImkL8Mp0u5GojmEHSWtgVkT8BPgc8Hlgg6SlkqakRS8AzgbWSLpL0htGeFyzmpwULM/Wk1TuQNKHT1KxrwOeBWalywYdVfH7M8BfR8TUip+eiFj2MmOYRNIdtQ4gIj4bEQuBeSTdSB9Ml/88Is4HDifp5vrmCI9rVpOTguXZN4FzJJ0uqRP4AEkX0E+Bu4ECcJWkDkm/D7y+YtsvAVdK+vV0QHiSpHMkTR5hDP8XuEzSgnQ84m9IurueknRKuv9OYCewByimYx6XSDo07fbaBhRfxt+DWZmTguVWRDwKXAr8E7CJZFD63IjYGxF7gd8H/hB4gWT8YXnFtitIxhU+l65/PC070hh+DHwUuIWkdfJrwJJ09RSS5PMCSRfTZpJxD4B3Ak9J2gZcmZ6H2csmv2THzMwGuaVgZmZlTgpmZlbmpGBmZmVOCmZmVtYx3gGM1GGHHRZz5swZ7zDMzA4qK1eu3BQRvcOVO+iSwpw5c1ixYsV4h2FmdlCRtGb4Uu4+MjOzCk4KZmZW5qRgZmZlB92YQi0DAwOsXbuWPXv2jHcomevu7mb27Nl0dnaOdyhm1oJaIimsXbuWyZMnM2fOHF46qWVriQg2b97M2rVrmTt37niHY2YtqCW6j/bs2cOMGTNaOiEASGLGjBm5aBGZ2fhoiaQAtHxCGJSX8zSz8dES3UcvR0SwacdeiqVktlgJZkzqoqO9ZfKlmVnTcl/z7dxb5Nmtu9m4fQ8bt+9hw7Y99O94cUT72LJlC1/4whdGfOyzzz6bLVu2jHg7M7Os5D4p7NmbvLDquCOmcMLsqUzp7mTLrgFG8p6JekmhWGz8Mqzvfve7TJ06dWQBm5llKPdJYfdAkY62NjrT7qJpk7oYKJbY/mKh6X1cc801PPHEEyxYsIBTTjmFN73pTVx88cUcf/zxALz1rW9l4cKFzJs3j6VLl5a3mzNnDps2beKpp57iuOOO4/LLL2fevHmceeaZ7N69e2xP1MysCS03pvCX336Ih9dva7r87oEiAro728vLdu0t0N4mJnQky1535BSuO3de3X188pOf5MEHH2T16tXceeednHPOOTz44IPl20ZvuOEGpk+fzu7duznllFO44IILmDFjxkv28dhjj7Fs2TK+9KUv8fa3v51bbrmFSy/1GxbNbP/KfUuhFEFb20vv6Oloa6NQCkb7otLXv/71L3mO4LOf/SwnnngiixYt4plnnuGxxx4bss3cuXNZsGABAAsXLuSpp54a5dHNzEav5VoKjb7RV9u9t8hjG7dz1PQepvZ0VSwv8NjGHcyaOpEZh0wYcQyTJk0q/37nnXdy++23c/fdd9PT08Npp51W8zmDCRP2Hae9vd3dR2Y2LnLdUtgzkAwEV3YdDX7u7mznhV0DTe1n8uTJbN++vea6rVu3Mm3aNHp6evjlL3/JPffc8/KCNjPLUMu1FEZi90ARSUzoeGlulMS0ni6e3bqbF3bupb1NIJjU1U5729A8OmPGDE499VTmz5/PxIkTmTlzZnndWWedxfXXX88JJ5zAMcccw6JFizI/LzOz0dJIbr0c8c6l9wPvAQJ4ALgsIob0nUi6ELgJOCUiGr5Bp6+vL6pfsvPII49w3HHHjTi+X/XvoBjBaw6fPGTdQLHEL5/b/pJbU6f3dDF7es+IjzPWRnu+ZpZfklZGRN9w5TLrPpI0C7gK6IuI+UA7sKRGuclpuXuziqWWiGDPQJGJVV1Hgzrb2zhm5iG8+vDkZ+rELrbsHqBQLO3PMM3M9qusxxQ6gImSOoAeYH2NMp8A/g7Yr7O8DRSDQimGjCdU6upop6erg56uDnond1GKYEuT4wxmZgejzJJCRKwDPg08DTwLbI2IH1aWkXQS8MqI+E6jfUm6QtIKSSv6+/vHJL7BQeZ6LYVqE9PksHnn3hE97WxmdjDJsvtoGnA+MBc4Epgk6dKK9W3AZ4APDLeviFgaEX0R0dfb2zsm8e2786j5v4Lpk7p4sVBk5wiedjYzO5hk2X10BvBkRPRHxACwHHhjxfrJwHzgTklPAYuA2yQNOxAyFnYPFOnqaKt5N1E9Uyd20t4mNu/cm2FkZmbjJ8uk8DSwSFKPkpcAnA48MrgyIrZGxGERMSci5gD3AOcNd/fRWNkzUGq662hQW1tyq+q23QUGPOBsZi0os+cUIuJeSTcDq4ACcB+wVNLHgRURcVtWxx5OsRS8WCgytWfk7zmeMamLTTte5Onnd3HoxE4mdbWXJ9Nr1tRDp7Bla/PzM1UrlYIX3FoxGxdT0h6DShHB1t0DZD3cOKGzjZ6ubB8vy3TvEXEdcF3V4o/VKXtalrFUqvckczMmdLYzc0o3z+/cy/oto5uKohTw8LOjTwobtu7hnE/8aNTbm9nonfrqGdz4npc+hPr3P/pv/uknj2d+7Ct/+9e4ZvGxmR4jl080l9J03tE2uldbzpzSzcwp3ewtlNi1t8DHPnIts486ij+6/L0A/N3ffAJJ3P1f/8mWLVsoDAzw4Y/+BYvfci6QvN3tyKkTRx3/i5s6+YtzXzfq7c1sdO57Zgv/tno9v+rfwat6DwGgUCyx7GfPcPJRUznvxCMzPf7xsw/NdP/Qiknhe9fAcw80LDKxVOJVAyW6u9qTGno4rzgeFn9yyOKujja6Orq47A8u4eqrr+bP3n8VAN/51nK+//3v85EPfZApU6awadMmFi1axKUXXYAkBBw2ion2BvVP6OAPF8wdvqCZjanF2/bw7fvXs3zVOv70d48B4N8f62fTjhf5m9+bz5nzXjHOEb58uZ4Qb6ycdNJJbNy4kfXr13P//fczbdo0jjjiCK699lpOOOEEzjjjDNatW8eGDRvGO1QzexlmTunmN17Ty633raOUvtf9llXrmD6pi9OOOXycoxsbrddSqPGNvtrOXXtZ8/wuXnP4ZCZ2jXxcoZYLL7yQm2++meeee44lS5Zw44030t/fz8qVK+ns7GTOnDk1p8w2s4PLBSfP4n1fX809T25m3hGH8qOHN3Dx64+iq6M1vmO3XlJowuANAs30HDVryZIlXH755WzatIm77rqLb37zmxx++OF0dnZyxx13sGbNmrE7mJmNmzNf9woOmdDBLSvX8eTRO9lbKHHBybPHO6wxk++kMIb7nDdvHtu3b2fWrFkcccQRXHLJJZx77rn09fWxYMECjj022zsGzGz/mNjVzjnHH8G3f7GeXz63jdfOPIT5s6aMd1hjJp9JIc0KY9lSAHjggX0D3Icddhh33313zXI7duwY2wOb2X51wcLZfGPFMzy0fhvXLD4WjXVlMo5aoxNsxLJoK5hZXpwyZxpHTe+hTfB7J80a73DGlFsKZmYjJIlrzz6WJ/p3MnNK93iHM6ZaJilERNNNuIO5neBpu80ODGfNP2K8Q8hES3QfdXd3s3nz5qYrzIO1pRARbN68me7u1vpmYmYHjpZoKcyePZu1a9fS7At4tu8ZYOvuAu3bumk7yDJDd3c3s2e3zu1vZnZgaYmk0NnZydy5zU/78Pk7HudTP3iUR//qLCZ0jM3Da2ZmraAluo9GqlBM+o86R/CCHTOzPMhlrVgolZCSl+aYmdk+OU0KMepps83MWlkuk0KxFHS468jMbIhc1owDxZJbCmZmNeQyKRRLQXu7k4KZWbVcJoWCu4/MzGrKtGaU9H5JD0l6UNIySd1V6/9E0sOSfiHpx5KOzjKeQQV3H5mZ1ZRZUpA0C7gK6IuI+UA7sKSq2H3p+hOAm4G/yyqeSoVS0O6kYGY2RNZ9KB3AREkdQA+wvnJlRNwREbvSj/cA+2X+hmIp6PSYgpnZEJklhYhYB3waeBp4FtgaET9ssMm7ge/VWiHpCkkrJK1odn6jRgpFtxTMzGrJsvtoGnA+MBc4Epgk6dI6ZS8F+oBP1VofEUsjoi8i+np7e192bIVSyQPNZmY1ZFkzngE8GRH9ETEALAfeWF1I0hnAR4DzIuLFDOMpK5aCDncfmZkNkWVSeBpYJKlHydtvTgceqSwg6STgiyQJYWOGsbzEQNHTXJiZ1ZLlmMK9JHcUrQIeSI+1VNLHJZ2XFvsUcAhwk6TVkm7LKp5KRd99ZGZWU6bvU4iI64DrqhZ/rGL9GVkev56BYomOdo8pmJlVy2XNWPQsqWZmNeUyKRRK4ZaCmVkNuawZk1tS3VIwM6uWz6Tgh9fMzGrKZVLwNBdmZrXlMikkE+Ll8tTNzBrKZc3oMQUzs9pymRSKfqLZzKymXCaFAc99ZGZWUy6Tgqe5MDOrLZdJIXkdZy5P3cysoVzWjAVPc2FmVlNuk0K7xxTMzIbIZVIoloJOdx+ZmQ2Ru5oxIjzQbGZWR+6SQqEUAB5TMDOrIXdJoTiYFDx1tpnZELmrGQeKJcAtBTOzWnKXFAZbCh5TMDMbKtOkIOn9kh6S9KCkZZK6q9ZPkPQNSY9LulfSnCzjgX1jCp4628xsqMySgqRZwFVAX0TMB9qBJVXF3g28EBGvBj4D/G1W8QwqFAdbCrlrJJmZDSvrmrEDmCipA+gB1letPx/4Wvr7zcDpkjL9Cl8oeUzBzKyezJJCRKwDPg08DTwLbI2IH1YVmwU8k5YvAFuBGdX7knSFpBWSVvT397+suPbdfeSkYGZWLcvuo2kkLYG5wJHAJEmXVhersWkMWRCxNCL6IqKvt7f3ZcU1UPRAs5lZPVl2H50BPBkR/RExACwH3lhVZi3wSoC0i+lQ4PkMY9rXUvCYgpnZEFnWjE8DiyT1pOMEpwOPVJW5DXhX+vuFwE8iYkhLYSyVxxTcfWRmNkSWYwr3kgwerwIeSI+1VNLHJZ2XFvsKMEPS48CfANdkFc+gwbuPPNBsZjZUR5Y7j4jrgOuqFn+sYv0e4G1ZxlCt4IfXzMzqyl3HerH88FruTt3MbFi5qxkL6dxHbimYmQ2Vv6TgaS7MzOrKXVLYNyFe7k7dzGxYuasZPXW2mVl9uUsKnubCzKy+3CWFAb+O08ysrtwlhWJp8O6j3J26mdmwclcz+olmM7P68pcUPKZgZlZXbpOCH14zMxsqd0mhmN6S2ukxBTOzIXJXM5ZbCu4+MjMbIrdJwQPNZmZD5S4p+M1rZmb15a5m9DQXZmb15S4pFEuBBG1OCmZmQ+QuKRRK4TuPzMzqyF3tWCiW/IyCmVkdTSUFSe+TNEWJr0haJenMrIPLQqEUHk8wM6uj2ZbCH0XENuBMoBe4DPhkow0kHSNpdcXPNklXV5U5VNK3Jd0v6SFJl43qLEagWApPcWFmVkdHk+UGa9GzgX+JiPslNaxZI+JRYAGApHZgHXBrVbE/Bh6OiHMl9QKPSroxIvY2fQYjNFAMz5BqZlZHs7XjSkk/JEkKP5A0GSiN4DinA09ExJqq5QFMThPMIcDzQGEE+x2xYqnk7iMzszqabSm8m+Rb/68iYpek6SRdSM1aAiyrsfxzwG3AemAycFFEDEk2kq4ArgA46qijRnDYoQruPjIzq6vZlsIbgEcjYoukS4E/B7Y2s6GkLuA84KYaq38XWA0cSZJ0PidpSnWhiFgaEX0R0dfb29tkyLUVih5oNjOrp9mk8M/ALkknAn8GrAH+tcltFwOrImJDjXWXAcsj8TjwJHBsk/sdlWIpfEuqmVkdzSaFQkQEcD7wjxHxjyTdPc14B7W7jgCeJhlvQNJM4BjgV03ud1QKpRKd7R5oNjOrpdkxhe2SPgy8E/jN9G6izuE2ktQDvBl4b8WyKwEi4nrgE8BXJT1AcofThyJi08hOYWQKRbcUzMzqaTYpXARcTPK8wnOSjgI+NdxGEbELmFG17PqK39eTPPuw3/jhNTOz+prqR4mI54AbgUMlvQXYExHNjikcUJKH19x9ZGZWS7PTXLwd+BnwNuDtwL2SLswysKwMeO4jM7O6mu0++ghwSkRsBEifPr4duDmrwLJSLAUTOt1SMDOrpdnasW0wIaQ2j2DbA0qh5GkuzMzqabal8H1JP2DfraUXAd/NJqRsFTzNhZlZXU0lhYj4oKQLgFNJbh1dGhHVk9sdFPxEs5lZfc22FIiIW4BbMoxlv/DU2WZm9TVMCpK2k8xkOmQVEBExZJ6iA53HFMzM6muYFCKi2aksDhqFUolOdx+ZmdWUu6/MnubCzKy+/CUFjymYmdWVu6RQLAUdHlMwM6spd7Wjp7kwM6svd0mh6FlSzczqyl1SKHiWVDOzunJXOxaKnubCzKyeXCWFUikoBR5TMDOrI1dJoRjJw9mdviXVzKymXCWFQjFJCp7mwsystsxqR0nHSFpd8bNN0tU1yp2Wrn9I0l1ZxQPJFBeAxxTMzOpoepbUkYqIR4EFAJLagXXAS6bbljQV+AJwVkQ8LenwrOKB5HZUwE80m5nVsb/6UU4HnoiINVXLLwaWR8TTAFVvdxtzA2n3kVsKZma17a+ksIR9b22r9FpgmqQ7Ja2U9Ae1NpZ0haQVklb09/ePOojBloLHFMzMasu8dpTUBZwH3FRjdQewEDgH+F3go5JeW10oIpZGRF9E9PX29o46lvKYgruPzMxqymxMocJiYFVEbKixbi2wKSJ2Ajsl/TtwIvDfWQRScPeRmVlD+6Mf5R3U7joC+DfgNyV1SOoBfh14JKtACuXuIycFM7NaMm0ppBX9m4H3Viy7EiAiro+IRyR9H/gFUAK+HBEPZhXP4JhCp+c+MjOrKdOkEBG7gBlVy66v+vwp4FNZxjFooJiMKbilYGZWW66+MpefU3BSMDOrKVdJoVB+eC1Xp21m1rRc1Y6Foqe5MDNrJFdJwd1HZmaN5SopFDz3kZlZQzlLCoN3H+XqtM3Mmpar2tFPNJuZNZarpOCps83MGstVUhjwQLOZWUO5SgrF8pvXcnXaZmZNy1XtuO8dzW4pmJnVkq+k4DEFM7OG8pkU3H1kZlZTrmrHoqe5MDNrKFdJofySHXcfmZnVlMuk0OnuIzOzmnJVOxb8kh0zs4bylRT88JqZWUO5SgrFUtAmaHNSMDOrKVdJYaAYvh3VzKyBzGpIScdIWl3xs03S1XXKniKpKOnCrOKBZJoLjyeYmdXXkdWOI+JRYAGApHZgHXBrdbl03d8CP8gqlkGFUvhpZjOzBvZXX8rpwBMRsabGuv8B3AJszDqIQjE8yGxm1sD+SgpLgGXVCyXNAn4PuL7RxpKukLRC0or+/v5RB1Eohd+6ZmbWQOY1pKQu4Dzgphqr/wH4UEQUG+0jIpZGRF9E9PX29o46lmKpRKe7j8zM6spsTKHCYmBVRGyosa4P+LokgMOAsyUVIuJbWQRSKIYHms3MGtgfSeEd1Og6AoiIuYO/S/oq8J2sEgKkA81OCmZmdWXafSSpB3gzsLxi2ZWSrszyuPUUS0FHu8cUzMzqybSlEBG7gBlVy2oOKkfEH2YZC8BAseSWgplZA7n62lwseUzBzKyRXCWFgruPzMwaylUNWSi5+8jMrJF8JQXfkmpm1lCukkKxFH54zcysgVwlhQFPc2Fm1lCuashiqUSnu4/MzOrKVVLwmIKZWWP5Sgp+n4KZWUO5SgrFkl/HaWbWSK5qSD+nYGbWWL6SgscUzMwayldS8DQXZmYN5aqGLPp9CmZmDeUqKQwUS+4+MjNrIFdJwdNcmJk1lqukUPA0F2ZmDeWqhiz4zWtmZg3lJimUSkEp8BPNZmYNZJYUJB0jaXXFzzZJV1eVuUTSL9Kfn0o6Mat4ihEAbimYmTXQkdWOI+JRYAGApHZgHXBrVbEngd+OiBckLQaWAr+eRTyFYpIUPKZgZlZfZkmhyunAExGxpnJhRPy04uM9wOysAiiUSgC++8jMrIH99bV5CbBsmDLvBr5Xa4WkKyStkLSiv79/VAHsayk4KZiZ1ZN5UpDUBZwH3NSgzJtIksKHaq2PiKUR0RcRfb29vaOKo1DymIKZ2XD2R/fRYmBVRGyotVLSCcCXgcURsTmrIIqDScFzH5mZ1bU/ash3UKfrSNJRwHLgnRHx31kGMVBMxhTcfWRmVl+mLQVJPcCbgfdWLLsSICKuBz4GzAC+IAmgEBF9WcRSdPeRmdmwMk0KEbGLpNKvXHZ9xe/vAd6TZQyDCu4+MjMbVm5qyMFbUt1SMDOrLz9JwbekmpkNKzdJYXBMwQ+vmZnVl5ukMNh95GkuzMzq21/TXIy7I+/5S77edS/H3T4F/qtzvMMxMxu5VxwPiz+Z6SFy87U5nSQVuffIzKyu3LQUHjv5z3nX6p9xy9lvYOHR08c7HDOzA1JuWgrF8i2puTllM7MRy00N6VtSzcyGl5+kUH6i2UnBzKye3CSFmVO6Ofv4V3DoRN95ZGZWT24GmhcePY2FRy8c7zDMzA5ouWkpmJnZ8JwUzMyszEnBzMzKnBTMzKzMScHMzMqcFMzMrMxJwczMypwUzMysTDE4p/RBQlI/sGaUmx8GbBrDcA4WeTzvPJ4z5PO883jOMPLzPjoieocrdNAlhZdD0oqI6BvvOPa3PJ53Hs8Z8nneeTxnyO683X1kZmZlTgpmZlaWt6SwdLwDGCd5PO88njPk87zzeM6Q0XnnakzBzMway1tLwczMGnBSMDOzstwkBUlnSXpU0uOSrhnveLIg6ZWS7pD0iKSHJL0vXT5d0o8kPZb+OW28Y82CpHZJ90n6Tvp5rqR70/P+hqSu8Y5xLEmaKulmSb9Mr/kb8nCtJb0//ff9oKRlkrpb8VpLukHSRkkPViyreX2V+Gxav/1C0smjPW4ukoKkduDzwGLgdcA7JL1ufKPKRAH4QEQcBywC/jg9z2uAH0fEa4Afp59b0fuARyo+/y3wmfS8XwDePS5RZecfge9HxLHAiSTn3tLXWtIs4CqgLyLmA+3AElrzWn8VOKtqWb3ruxh4TfpzBfDPoz1oLpIC8Hrg8Yj4VUTsBb4OnD/OMY25iHg2Ilalv28nqSRmkZzr19JiXwPeOj4RZkfSbOAc4MvpZwG/A9ycFmmp85Y0Bfgt4CsAEbE3IraQg2tN8hrhiZI6gB7gWVrwWkfEvwPPVy2ud33PB/41EvcAUyUdMZrj5iUpzAKeqfi8Nl3WsiTNAU4C7gVmRsSzkCQO4PDxiywz/wD8GVBKP88AtkREIf3catf8VUA/8C9pl9mXJU2ixa91RKwDPg08TZIMtgIrae1rXane9R2zOi4vSUE1lrXsvbiSDgFuAa6OiG3jHU/WJL0F2BgRKysX1yjaSte8AzgZ+OeIOAnYSYt1FdWS9qGfD8wFjgQmkXSdVGula92MMfv3npeksBZ4ZcXn2cD6cYolU5I6SRLCjRGxPF28YbApmf65cbziy8ipwHmSniLpGvwdkpbD1LSLAVrvmq8F1kbEvennm0mSRKtf6zOAJyOiPyIGgOXAG2nta12p3vUdszouL0nh58Br0jsUukgGpm4b55jGXNqP/hXgkYj4+4pVtwHvSn9/F/Bv+zu2LEXEhyNidkTMIbm2P4mIS4A7gAvTYi113hHxHPCMpGPSRacDD9Pi15qk22iRpJ703/vgebfsta5S7/reBvxBehfSImDrYDfTSOXmiWZJZ5N8e2wHboiIvx7nkMacpN8A/gN4gH1969eSjCt8EziK5D/V2yKiegCrJUg6DfjTiHiLpFeRtBymA/cBl0bEi+MZ31iStIBkYL0L+BVwGckXvZa+1pL+EriI5G67+4D3kPSft9S1lrQMOI1kiuwNwHXAt6hxfdME+TmSu5V2AZdFxIpRHTcvScHMzIaXl+4jMzNrgpOCmZmVOSmYmVmZk4KZmZU5KZiZWZmTgtl+JOm0wVlczQ5ETgpmZlbmpGBWg6RLJf1M0mpJX0zf1bBD0v+StErSjyX1pmUXSLonncf+1oo57l8t6XZJ96fb/Fq6+0Mq3oNwY/rgkdkBwUnBrIqk40iemD01IhYAReASksnXVkXEycBdJE+YAvwr8KGIOIHkafLB5TcCn4+IE0nm5xmcduAk4GqSd3u8imTuJrMDQsfwRcxy53RgIfDz9Ev8RJKJx0rAN9Iy/wdYLulQYGpE3JUu/xpwk6TJwKyIuBUgIvYApPv7WUSsTT+vBuYA/5n9aZkNz0nBbCgBX4uID79kofTRqnKN5ohp1CVUOSdPEf8/tAOIu4/MhvoxcKGkw6H8XtyjSf6/DM7EeTHwnxGxFXhB0m+my98J3JW+x2KtpLem+5ggqWe/noXZKPgbilmViHhY0p8DP5TUR+1XAAAAaElEQVTUBgwAf0zyIpt5klaSvPHronSTdwHXp5X+4GylkCSIL0r6eLqPt+3H0zAbFc+SatYkSTsi4pDxjsMsS+4+MjOzMrcUzMyszC0FMzMrc1IwM7MyJwUzMytzUjAzszInBTMzK/v/G2VufJyPBBUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 53.8462%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aashi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore: [0.  0.7]\n",
      "Predicted   1  All\n",
      "Actual            \n",
      "0          12   12\n",
      "1          14   14\n",
      "All        26   26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "model.load_weights(bestModelSavedName)\n",
    "\n",
    "# get index of predicted part for each image in the test image set\n",
    "part_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(part_predictions)==np.argmax(test_targets, axis=1))/len(part_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "print (\"Fscore:\", f1_score(np.argmax(test_targets, axis=1), part_predictions, average=None) )\n",
    "\n",
    "y_actu = pd.Series(np.argmax(test_targets, axis=1), name='Actual')\n",
    "y_pred = pd.Series(part_predictions, name='Predicted')\n",
    "\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print (df_confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
